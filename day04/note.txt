一、Items的声明
	1、Items的类声明，如下：
		class Product(scrapy.Item):
			name = scrapy.Field()
			price = scrapy.Field()
			stock = scrapy.Field()
			last_update = scrapy.Field(serializer=str)
	实例的创建和Python的Dict一样，具有类似的API方法：
		创建item：
		>>> product = Product(name='Desktop PC', price=1000)
		>>> print product
			Product(name='Desktop PC', price=1000)
			获取字段的值
		>>> product['name']
			Desktop PC
		>>> product.get('name')
			Desktop PC

		>>> product['price']
			1000

		>>> product['last_updated']
			Traceback (most recent call last):
			    ...
			KeyError: 'last_updated'

		>>> product.get('last_updated', 'not set')
			not set

		>>> product['lala'] # getting unknown field
			Traceback (most recent call last):
			    ...
			KeyError: 'lala'

		>>> product.get('lala', 'unknown field')
			'unknown field'

		>>> 'name' in product  # is name field populated?
			True

		>>> 'last_updated' in product  # is last_updated populated?
			False

		>>> 'last_updated' in product.fields  # is last_updated a declared field?
			True

		>>> 'lala' in product.fields  # is lala a declared field?
			False
			设置字段的值
		>>> product['last_updated'] = 'today'
		>>> product['last_updated']
			today

		>>> product['lala'] = 'test' # setting unknown field
			Traceback (most recent call last):
		    ...
			KeyError: 'Product does not support field: lala'

		Items复制：
			>>> product2 = Product(product)
			>>> print product2
			Product(name='Desktop PC', price=1000)

			>>> product3 = product2.copy()
			>>> print product3
			Product(name='Desktop PC', price=1000)
			
		Items转字典：
			>>> dict(product) # create a dict from all populated values
			{'price': 1000, 'name': 'Desktop PC'}

		字典转Items：
			>>> Product({'name': 'Laptop PC', 'price': 1500})
			Product(price=1500, name='Laptop PC')

			# 在Items中不存在的字典字段转换为Items会报错
			>>> Product({'name': 'Laptop PC', 'lala': 1500}) # warning: unknown field in dict
			Traceback (most recent call last):
			    ...
			KeyError: 'Product does not support field: lala'

	2、Item对象：
		class scrapy.item.Item([arg])
			返回一个根据给定的参数可选初始化的item。
			Item复制了标准的 dict API 。包括初始化函数也相同。Item唯一额外添加的属性是:
			fields
			一个包含了item所有声明的字段的字典，而不仅仅是获取到的字段。该字典的key是字段(field)的名字，值是 Item声明中使用到的Field对象。

	3、字段(Field)对象：
		class scrapy.item.Field([arg])
			Field 仅仅是内置的 dict 类的一个别名，并没有提供额外的方法或者属性。换句话说， Field 对象完完全全就是Python字典(dict)。被用来基于类属性(class attribute)的方法来支持item声明语法。

二、Item Loaders
	已经知道网页的基本解析流程就是先通过css/xpath方法进行解析，然后再把值封装到Item中，如果有特殊需要的话还要对解析到的数据进行转换处理，这样当解析代码或者数据转换要求过多的时候，会导致代码量变得极为庞大，从而降低了可维护性。同时在sipider中编写过多的数据处理代码某种程度上也违背了单一职责的代码设计原则。我们需要使用一种更加简洁的方式来获取与处理网页数据，ItemLoader 就是用来完成这件事情的。
	1、用ItemLoaders装载Items
		先实例化ItemLoader，然后使用ItemLoader的Selectors进行数据的处理添加。最终通过实例调用load_item()方法返回一个已经填充好数据的Item对象，例如：
			from scrapy.loader import ItemLoader
			from itemTest.items import Product

			def parse(self, response):
			    l = ItemLoader(item=Product(), response=response)
			    l.add_xpath('name', '//div[@class="product_name"]')
			    l.add_xpath('name', '//div[@class="product_title"]')
			    l.add_xpath('price', '//p[@id="price"]')
			    l.add_css('stock', 'p#stock]')
			    l.add_value('last_updated', 'today') # you can also use literal values
			    return l.load_item()

	2、声明Item Loaders
		Item Loaders 的声明类似于Items，以class的语法来声明：

		from scrapy.contrib.loader import ItemLoader
		from scrapy.contrib.loader.processor import TakeFirst, MapCompose, Join
		class ProductLoader(ItemLoader):
		    default_output_processor = TakeFirst()
		    name_in = MapCompose(unicode.title)
		    name_out = Join()
		    price_in = MapCompose(unicode.strip)
		    # ...
		input processors 以_in为后缀来声明，output processors 以_out 为后缀来声明。也可以用ItemLoader.default_input_processor 和ItemLoader.default_output_processor属性来声明默认的 input/output processors。

	3、声明Input and Output Processors(输入/输出处理器)
		input and output processors可以在定义Item Loaders的时候声明，这是非常普遍的使用方法。但是，你也可以在定义Item的时候声明输入输出处理器。下面是例子：

		import scrapy
		from scrapy.contrib.loader.processor import Join, MapCompose, TakeFirst
		from w3lib.html import remove_tags

		def filter_price(value):
		    if value.isdigit():
		        return value

		class ProductItem(scrapy.Item):
		    name = scrapy.Field(
		        input_processor=MapCompose(remove_tags),
		        output_processor=Join(),
		    )
		    price = scrapy.Field(
		        input_processor=MapCompose(remove_tags, filter_price),
		        output_processor=TakeFirst(),
		    )

		使用Item：
		>>> from scrapy.contrib.loader import ItemLoader
		>>> il = ItemLoader(item=Product())
		>>> il.add_value('name', [u'Welcome to my', u'<strong>website</strong>'])
		>>> il.add_value('price', [u'&euro;', u'<span>1000</span>'])
		>>> il.load_item()
		{'name': u'Welcome to my website', 'price': u'1000'}

		关于集中声明 input and output processors方式的优先级排序如下：
		1.在Item Loader 中声明的 field-specific 属性: field_in and field_out (most precedence)
		2.Item中的字段元数据(input_processor and output_processor key)
		3.Item Loader 默认处理器: ItemLoader.default_input_processor() and ItemLoader.default_output_processor() (least precedence)

	4、ItemLoader上下文的数据
		转换长度的方法：
		def parse_length(text, loader_context):
		    unit = loader_context.get('unit', 'm')
		    # ... length parsing code goes here ...
		    return parsed_length

		修改Item Loader 上下文数据的三种方法：
		1.By modifying the currently active Item Loader context (context attribute):
			loader = ItemLoader(product)
			loader.context['unit'] = 'cm'

		2.On Item Loader instantiation(实例化) (the keyword arguments of Item Loader constructor(构造函数) are stored in the Item Loader context):
			loader = ItemLoader(product, unit='cm')

		3.On Item Loader declaration(申报), for those input(投入)/output(输出) processors that support instantiating(例示) them with an Item Loader context. MapCompose is one of them:
			class ProductLoader(ItemLoader):
			    length_out = MapCompose(parse_length, unit='cm')	

	5、ItemLoader实例的方法和属性
		看官方文档：https://doc.scrapy.org/en/latest/topics/loaders.html#itemloader-objects
		常用的方法如：add_xpath/add_css/add_value/load_item
	6、Nested Loaders(嵌套加载器)
		Example:

		<footer>
		    <a class="social" href="http://facebook.com/whatever">Like Us</a>
		    <a class="social" href="http://twitter.com/whatever">Follow Us</a>
		    <a class="email" href="mailto:whatever@example.com">Email Us</a>
		</footer>
		Without nested loaders, you need to specify the full xpath (or css) for each value that you wish to extract.

		Example:
		loader = ItemLoader(item=Item())
		# load stuff not in the footer
		loader.add_xpath('social', '//footer/a[@class = "social"]/@href')
		loader.add_xpath('email', '//footer/a[@class = "email"]/@href')
		loader.load_item()
		Instead, you can create a nested loader with the footer selector and add values relative to the footer. The functionality is the same but you avoid repeating the footer selector.

		Example:
		loader = ItemLoader(item=Item())
		# load stuff not in the footer
		footer_loader = loader.nested_xpath('//footer')
		footer_loader.add_xpath('social', 'a[@class = "social"]/@href')
		footer_loader.add_xpath('email', 'a[@class = "email"]/@href')
		# no need to call footer_loader.load_item()
		loader.load_item()
	7、复用和扩展Item Loaders

	8、内置的处理器（processors）
		查看官方文档：https://doc.scrapy.org/en/latest/topics/loaders.html#module-scrapy.loader.processors
		常用的处理器：Join、Compose、MapCompose、TakeFirst